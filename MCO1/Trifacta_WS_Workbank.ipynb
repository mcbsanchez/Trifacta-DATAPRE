{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessible-syndication",
   "metadata": {},
   "source": [
    "# Job Portal - WORKBANK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-composite",
   "metadata": {},
   "source": [
    "## Imports used (to be described)\n",
    "\n",
    "* `os` - a module that provides functions to interact with the operating system.\n",
    "* `pandas` - is a tool that helps analyze data.\n",
    "* `numpy` - Library that contains multiple functions that help ease the work with arrays, matrices, and alike to better reassemble data.\n",
    "* `json` - enables import and export from and to JSON files\n",
    "* `re` - Short for Regular Expressions, help recognize patterns on strings of data and is used to orderly reassemble them.\n",
    "* `gensim` - Library that efficiently handles large, unmanaged text collections of data.\n",
    "* `nltk` - Short for Natural Language Toolkit. It helps the program to apply human language data to statistical natural language.\n",
    "* `requests` - Requests allows the program to send HTTP requests easily.\n",
    "* `Seaborn` - A library in python that is used to better visualize data through drawing informative graphs.\n",
    "* `math` - Imported library that allows quick computations of mathematical tasks\n",
    "* `gensim.utils` `simple_preprocess` - used to preprocess text by making them lower-cased, and transforming the words to their original form (de-tokenizing)\n",
    "* `gensim.parsing.preprocessing` `STOPWORDS` - stop words common words that do not have value and are often removed in pre-processing\n",
    "* `gensim` `corpora` - used to work with corpus and words\n",
    "* `gensim` `models` - used for topic modelling and model training\n",
    "* `nltk.stem` `WordNetLemmatizer` - used for grouping similar strings together\n",
    "* `bs4` `BeautifulSoup` - library used to web scrape HTML from websites\n",
    "* `datetime` `datetime` - An imported module in python to create an object that properly resembles date and time. Used for converting string of time into datetime format to month, day, and year.\n",
    "* `datetime` `timedelta` - used for finding delta of time ago with time scraped if date has minutes, hours, days, or weeks ago\n",
    "* `dateutil.relativedelta` `relativedelta` - used for finding delta of time ago with time scraped if date has months and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becoming-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import requests\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "today = datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-watershed",
   "metadata": {},
   "source": [
    "We will be using Beautiful Soup to scrape job posts from WorkBank.com\n",
    "The following are the relevant data that we will need to take from the website.\n",
    "- WORKBANK_JOB_TITLE - The title of the Job Post\n",
    "- WORKBANK_JOB_CATEGORY - The category of the Job Post with relation to the STEM field \n",
    "- WORKBANK_JOB_COMPANY - The Company which is looking for applications for the Job Post\n",
    "- WORKBANK_JOB_DATE - Date and time the Job Post was posted\n",
    "- WORKBANK_JOB_LOCATION - Location where the Job Post is assigned to\n",
    "- WORKBANK_JOB_STATUS - This determines the type of the job whether it is full time or not\n",
    "- WORKBANK_JOB_SALARY - Monthly salary of the job listing in Philippine Pesos (PHP)\n",
    "- WORKBANK_JOB_EDUCATION - Educational attainment requirements for the applicant\n",
    "- WORKBANK_JOB_DESCRIPTION - A detailed job description\n",
    "- WORKBANK_JOB_YEAR_WE - Years of Work Experience required for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKBANK_JOB_TITLE = []\n",
    "WORKBANK_JOB_CATEGORY = []\n",
    "WORKBANK_JOB_COMPANY = []\n",
    "WORKBANK_JOB_DATE = []\n",
    "WORKBANK_JOB_LOCATION = []\n",
    "WORKBANK_JOB_STATUS = []\n",
    "WORKBANK_JOB_SALARY = []\n",
    "WORKBANK_JOB_EDUCATION = []\n",
    "WORKBANK_JOB_DESCRIPTION = []\n",
    "WORKBANK_JOB_YEAR_WE = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-elimination",
   "metadata": {},
   "source": [
    "### CATEGORY - Information Communications Technology\n",
    "\n",
    "Since we are only looking for Job Posts in the STEM field, we will need to go over the website WorkBank.com and choose only the relevant categories, such as the Information Communications Technology. We will need to scrape every single page in that category result in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Communications Technology\n",
    "IT_WORKBANK_URL = 'https://www.workbank.com/job/information-communications-technology-job-openings?wb_q='\n",
    "IT_WORKBANK = requests.get(IT_WORKBANK_URL)\n",
    "IT_WORKBANK_soup = BeautifulSoup(IT_WORKBANK.content, 'html.parser')\n",
    "IT_WORKBANK_PP = IT_WORKBANK_soup.find_all('select',{'class':'wb-pagination-select'})\n",
    "if (len(IT_WORKBANK_PP)!=0):\n",
    "    IT_WORKBANK_NUMPAGES=len(IT_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    IT_WORKBANK_NUMPAGES=0\n",
    "IT_WORKBANK_PAGES=[]\n",
    "if (IT_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        IT_WORKBANK_PAGES.append('https://www.workbank.com/job/information-communications-technology-job-openings?page='+ str(i))\n",
    "else:\n",
    "    IT_WORKBANK_PAGES.append('https://www.workbank.com/job/information-communications-technology-job-openings?page=1')\n",
    "for i in range(len(IT_WORKBANK_PAGES)):\n",
    "    IT_WORKBANK_URLs = IT_WORKBANK_PAGES[i]\n",
    "    IT_WORKBANK_PAGE = requests.get(IT_WORKBANK_URLs)\n",
    "    IT_WORKBANK_PAGE_soup = BeautifulSoup(IT_WORKBANK_PAGE.content, 'html.parser')\n",
    "    IT_WORKBANK_JOBS = IT_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    IT_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(IT_WORKBANK_JOBS))\n",
    "    IT_WORKBANK_JOB_DATEs = IT_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(IT_WORKBANK_JOB_URLs)):\n",
    "        IT_WORKBANK_JOB_PAGE = requests.get(IT_WORKBANK_JOB_URLs[j])\n",
    "        IT_WORKBANK_JOB_PAGE_soup = BeautifulSoup(IT_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        IT_WORKBANK_JOB_PAGE_INFO1 = IT_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        IT_WORKBANK_JOB_TITLE = IT_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        IT_WORKBANK_JOB_COMPANY = IT_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        IT_WORKBANK_JOB_SALARY = IT_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        IT_WORKBANK_JOB_DATEPOSTED = IT_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        IT_WORKBANK_JOB_LOCATION = IT_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        IT_WORKBANK_JOB_INFO2 = IT_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        IT_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        IT_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        IT_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        IT_WORKBANK_JOB_CATEGORY = \"Information and Communications Technology\"\n",
    "        IT_WORKBANK_JOB_INFO3 = IT_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        IT_WORKBANK_JOB_DESCRIPTION = IT_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(IT_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(IT_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(IT_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(IT_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(IT_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(IT_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(IT_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_EDUCATION.append(IT_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_YEAR_WE.append(IT_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(IT_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-craft",
   "metadata": {},
   "source": [
    "### Souptest\n",
    "\n",
    "Getting the html of the URL of the Information Communications Technology job openings, it can be observed that it contains the list of jobs that we interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "souptest = BeautifulSoup(IT_WORKBANK.content, 'html.parser')\n",
    "souptest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-profit",
   "metadata": {},
   "source": [
    "### CATEGORY - Construction\n",
    "The same process is done for the other sources to expand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction\n",
    "CONSTRUCTION_WORKBANK_URL = 'https://www.workbank.com/job/construction-job-openings?wb_q='\n",
    "CONSTRUCTION_WORKBANK = requests.get(CONSTRUCTION_WORKBANK_URL)\n",
    "CONSTRUCTION_WORKBANK_soup = BeautifulSoup(CONSTRUCTION_WORKBANK.content, 'html.parser')\n",
    "CONSTRUCTION_WORKBANK_PP = CONSTRUCTION_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(CONSTRUCTION_WORKBANK_PP)!=0):\n",
    "    CONSTRUCTION_WORKBANK_NUMPAGES=len(CONSTRUCTION_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    CONSTRUCTION_WORKBANK_NUMPAGES=0\n",
    "CONSTRUCTION_WORKBANK_PAGES=[]\n",
    "if (CONSTRUCTION_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        CONSTRUCTION_WORKBANK_PAGES.append('https://www.workbank.com/job/construction-job-openings?page='+ str(i))\n",
    "else:\n",
    "    CONSTRUCTION_WORKBANK_PAGES.append('https://www.workbank.com/job/construction-job-openings?page=1')\n",
    "for i in range(len(CONSTRUCTION_WORKBANK_PAGES)):\n",
    "    CONSTRUCTION_WORKBANK_URLs = CONSTRUCTION_WORKBANK_PAGES[i]\n",
    "    CONSTRUCTION_WORKBANK_PAGE = requests.get(CONSTRUCTION_WORKBANK_URLs)\n",
    "    CONSTRUCTION_WORKBANK_PAGE_soup = BeautifulSoup(CONSTRUCTION_WORKBANK_PAGE.content, 'html.parser')\n",
    "    CONSTRUCTION_WORKBANK_JOBS = CONSTRUCTION_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    CONSTRUCTION_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(CONSTRUCTION_WORKBANK_JOBS))\n",
    "    CONSTRUCTION_WORKBANK_JOB_DATEs = CONSTRUCTION_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(CONSTRUCTION_WORKBANK_JOB_URLs)):\n",
    "        CONSTRUCTION_WORKBANK_JOB_PAGE = requests.get(CONSTRUCTION_WORKBANK_JOB_URLs[j])\n",
    "        CONSTRUCTION_WORKBANK_JOB_PAGE_soup = BeautifulSoup(CONSTRUCTION_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        CONSTRUCTION_WORKBANK_JOB_PAGE_INFO1 = CONSTRUCTION_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        CONSTRUCTION_WORKBANK_JOB_TITLE = CONSTRUCTION_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        CONSTRUCTION_WORKBANK_JOB_COMPANY = CONSTRUCTION_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        CONSTRUCTION_WORKBANK_JOB_SALARY = CONSTRUCTION_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        CONSTRUCTION_WORKBANK_JOB_DATEPOSTED = CONSTRUCTION_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        CONSTRUCTION_WORKBANK_JOB_LOCATION = CONSTRUCTION_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        CONSTRUCTION_WORKBANK_JOB_INFO2 = CONSTRUCTION_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        CONSTRUCTION_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(CONSTRUCTION_WORKBANK_JOB_INFO2))[0]\n",
    "        CONSTRUCTION_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(CONSTRUCTION_WORKBANK_JOB_INFO2))[0]\n",
    "        CONSTRUCTION_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        CONSTRUCTION_WORKBANK_JOB_CATEGORY = \"Construction\"\n",
    "        CONSTRUCTION_WORKBANK_JOB_INFO3 = CONSTRUCTION_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        CONSTRUCTION_WORKBANK_JOB_DESCRIPTION = CONSTRUCTION_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(CONSTRUCTION_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(CONSTRUCTION_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(CONSTRUCTION_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(CONSTRUCTION_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(CONSTRUCTION_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(CONSTRUCTION_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(CONSTRUCTION_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_EDUCATION.append(CONSTRUCTION_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_YEAR_WE.append(CONSTRUCTION_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(CONSTRUCTION_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-green",
   "metadata": {},
   "source": [
    "### CATEGORY - Design and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design and Architecture\n",
    "ARCHITECTURE_WORKBANK_URL = 'https://www.workbank.com/job/design-architecture-job-openings?wb_q='\n",
    "ARCHITECTURE_WORKBANK = requests.get(ARCHITECTURE_WORKBANK_URL)\n",
    "ARCHITECTURE_WORKBANK_soup = BeautifulSoup(ARCHITECTURE_WORKBANK.content, 'html.parser')\n",
    "ARCHITECTURE_WORKBANK_PP = ARCHITECTURE_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(ARCHITECTURE_WORKBANK_PP)!=0):\n",
    "    ARCHITECTURE_WORKBANK_NUMPAGES=len(ARCHITECTURE_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    ARCHITECTURE_WORKBANK_NUMPAGES=0\n",
    "ARCHITECTURE_WORKBANK_PAGES=[]\n",
    "if (ARCHITECTURE_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        ARCHITECTURE_WORKBANK_PAGES.append('https://www.workbank.com/job/design-architecture-job-openings?page='+ str(i))\n",
    "else:\n",
    "    ARCHITECTURE_WORKBANK_PAGES.append('https://www.workbank.com/job/design-architecture-job-openings?page=1')\n",
    "for i in range(len(ARCHITECTURE_WORKBANK_PAGES)):\n",
    "    ARCHITECTURE_WORKBANK_URLs = ARCHITECTURE_WORKBANK_PAGES[i]\n",
    "    ARCHITECTURE_WORKBANK_PAGE = requests.get(ARCHITECTURE_WORKBANK_URLs)\n",
    "    ARCHITECTURE_WORKBANK_PAGE_soup = BeautifulSoup(ARCHITECTURE_WORKBANK_PAGE.content, 'html.parser')\n",
    "    ARCHITECTURE_WORKBANK_JOBS = ARCHITECTURE_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    ARCHITECTURE_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(ARCHITECTURE_WORKBANK_JOBS))\n",
    "    ARCHITECTURE_WORKBANK_JOB_DATEs = ARCHITECTURE_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(ARCHITECTURE_WORKBANK_JOB_URLs)):\n",
    "        ARCHITECTURE_WORKBANK_JOB_PAGE = requests.get(ARCHITECTURE_WORKBANK_JOB_URLs[j])\n",
    "        ARCHITECTURE_WORKBANK_JOB_PAGE_soup = BeautifulSoup(ARCHITECTURE_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        ARCHITECTURE_WORKBANK_JOB_PAGE_INFO1 = ARCHITECTURE_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        ARCHITECTURE_WORKBANK_JOB_TITLE = ARCHITECTURE_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        ARCHITECTURE_WORKBANK_JOB_COMPANY = ARCHITECTURE_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        ARCHITECTURE_WORKBANK_JOB_SALARY = ARCHITECTURE_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        ARCHITECTURE_WORKBANK_JOB_DATEPOSTED = ARCHITECTURE_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        ARCHITECTURE_WORKBANK_JOB_LOCATION = ARCHITECTURE_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        ARCHITECTURE_WORKBANK_JOB_INFO2 = ARCHITECTURE_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        ARCHITECTURE_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(ARCHITECTURE_WORKBANK_JOB_INFO2))[0]\n",
    "        ARCHITECTURE_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(ARCHITECTURE_WORKBANK_JOB_INFO2))[0]\n",
    "        ARCHITECTURE_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        ARCHITECTURE_WORKBANK_JOB_CATEGORY = \"Design and Architecture\"\n",
    "        ARCHITECTURE_WORKBANK_JOB_INFO3 = ARCHITECTURE_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        ARCHITECTURE_WORKBANK_JOB_DESCRIPTION = ARCHITECTURE_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(ARCHITECTURE_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(ARCHITECTURE_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(ARCHITECTURE_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(ARCHITECTURE_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(ARCHITECTURE_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(ARCHITECTURE_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(ARCHITECTURE_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_EDUCATION.append(ARCHITECTURE_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_YEAR_WE.append(ARCHITECTURE_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(ARCHITECTURE_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-facial",
   "metadata": {},
   "source": [
    "### CATEGORY - Agriculture and Wildlife Conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agriculture and Wildlife Conservation\n",
    "AGRICULTURE_WORKBANK_URL = 'https://www.workbank.com/job/agriculture-wildlife-conservation-job-openings?wb_q='\n",
    "AGRICULTURE_WORKBANK = requests.get(AGRICULTURE_WORKBANK_URL)\n",
    "AGRICULTURE_WORKBANK_soup = BeautifulSoup(AGRICULTURE_WORKBANK.content, 'html.parser')\n",
    "AGRICULTURE_WORKBANK_PP = AGRICULTURE_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(AGRICULTURE_WORKBANK_PP)!=0):\n",
    "    AGRICULTURE_WORKBANK_NUMPAGES=len(AGRICULTURE_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    AGRICULTURE_WORKBANK_NUMPAGES=0\n",
    "AGRICULTURE_WORKBANK_PAGES=[]\n",
    "if (AGRICULTURE_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        AGRICULTURE_WORKBANK_PAGES.append('https://www.workbank.com/job/agriculture-wildlife-conservation-job-openings?page='+ str(i))\n",
    "else:\n",
    "    AGRICULTURE_WORKBANK_PAGES.append('https://www.workbank.com/job/agriculture-wildlife-conservation-job-openings?page=1')\n",
    "for i in range(len(AGRICULTURE_WORKBANK_PAGES)):\n",
    "    AGRICULTURE_WORKBANK_URLs = AGRICULTURE_WORKBANK_PAGES[i]\n",
    "    AGRICULTURE_WORKBANK_PAGE = requests.get(AGRICULTURE_WORKBANK_URLs)\n",
    "    AGRICULTURE_WORKBANK_PAGE_soup = BeautifulSoup(AGRICULTURE_WORKBANK_PAGE.content, 'html.parser')\n",
    "    AGRICULTURE_WORKBANK_JOBS = AGRICULTURE_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    AGRICULTURE_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(AGRICULTURE_WORKBANK_JOBS))\n",
    "    AGRICULTURE_WORKBANK_JOB_DATEs = AGRICULTURE_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(AGRICULTURE_WORKBANK_JOB_URLs)):\n",
    "        AGRICULTURE_WORKBANK_JOB_PAGE = requests.get(AGRICULTURE_WORKBANK_JOB_URLs[j])\n",
    "        AGRICULTURE_WORKBANK_JOB_PAGE_soup = BeautifulSoup(AGRICULTURE_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        AGRICULTURE_WORKBANK_JOB_PAGE_INFO1 = AGRICULTURE_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        AGRICULTURE_WORKBANK_JOB_TITLE = AGRICULTURE_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        AGRICULTURE_WORKBANK_JOB_COMPANY = AGRICULTURE_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        AGRICULTURE_WORKBANK_JOB_SALARY = AGRICULTURE_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        AGRICULTURE_WORKBANK_JOB_DATEPOSTED = AGRICULTURE_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        AGRICULTURE_WORKBANK_JOB_LOCATION = AGRICULTURE_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        AGRICULTURE_WORKBANK_JOB_INFO2 = AGRICULTURE_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        AGRICULTURE_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(AGRICULTURE_WORKBANK_JOB_INFO2))[0]\n",
    "        AGRICULTURE_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(AGRICULTURE_WORKBANK_JOB_INFO2))[0]\n",
    "        AGRICULTURE_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        AGRICULTURE_WORKBANK_JOB_CATEGORY = \"Agriculture and Wildlife Conservation\"\n",
    "        AGRICULTURE_WORKBANK_JOB_INFO3 = AGRICULTURE_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        AGRICULTURE_WORKBANK_JOB_DESCRIPTION = AGRICULTURE_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(AGRICULTURE_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(AGRICULTURE_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(AGRICULTURE_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(AGRICULTURE_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(AGRICULTURE_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(AGRICULTURE_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(AGRICULTURE_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_YEAR_WE.append(AGRICULTURE_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_EDUCATION.append(AGRICULTURE_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(AGRICULTURE_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-defeat",
   "metadata": {},
   "source": [
    "### CATEGORY - Environmental and Health Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environmental and Health Safety\n",
    "SAFETY_WORKBANK_URL = 'https://www.workbank.com/job/environmental-health-safety-job-openings?wb_q='\n",
    "SAFETY_WORKBANK = requests.get(SAFETY_WORKBANK_URL)\n",
    "SAFETY_WORKBANK_soup = BeautifulSoup(SAFETY_WORKBANK.content, 'html.parser')\n",
    "SAFETY_WORKBANK_PP = SAFETY_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(SAFETY_WORKBANK_PP)!=0):\n",
    "    SAFETY_WORKBANK_NUMPAGES=len(SAFETY_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    SAFETY_WORKBANK_NUMPAGES=0\n",
    "SAFETY_WORKBANK_PAGES=[]\n",
    "if (SAFETY_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        SAFETY_WORKBANK_PAGES.append('https://www.workbank.com/job/environmental-health-safety-job-openings?page='+ str(i))\n",
    "else:\n",
    "    SAFETY_WORKBANK_PAGES.append('https://www.workbank.com/job/environmental-health-safety-job-openings?page=1')\n",
    "for i in range(len(SAFETY_WORKBANK_PAGES)):\n",
    "    SAFETY_WORKBANK_URLs = SAFETY_WORKBANK_PAGES[i]\n",
    "    SAFETY_WORKBANK_PAGE = requests.get(SAFETY_WORKBANK_URLs)\n",
    "    SAFETY_WORKBANK_PAGE_soup = BeautifulSoup(SAFETY_WORKBANK_PAGE.content, 'html.parser')\n",
    "    SAFETY_WORKBANK_JOBS = SAFETY_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    SAFETY_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(SAFETY_WORKBANK_JOBS))\n",
    "    SAFETY_WORKBANK_JOB_DATEs = SAFETY_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(SAFETY_WORKBANK_JOB_URLs)):\n",
    "        SAFETY_WORKBANK_JOB_PAGE = requests.get(SAFETY_WORKBANK_JOB_URLs[j])\n",
    "        SAFETY_WORKBANK_JOB_PAGE_soup = BeautifulSoup(SAFETY_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        SAFETY_WORKBANK_JOB_PAGE_INFO1 = SAFETY_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        SAFETY_WORKBANK_JOB_TITLE = SAFETY_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        SAFETY_WORKBANK_JOB_COMPANY = SAFETY_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        SAFETY_WORKBANK_JOB_SALARY = SAFETY_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        SAFETY_WORKBANK_JOB_DATEPOSTED = SAFETY_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        SAFETY_WORKBANK_JOB_LOCATION = SAFETY_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        SAFETY_WORKBANK_JOB_INFO2 = SAFETY_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        SAFETY_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(SAFETY_WORKBANK_JOB_INFO2))[0]\n",
    "        SAFETY_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(SAFETY_WORKBANK_JOB_INFO2))[0]\n",
    "        SAFETY_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        SAFETY_WORKBANK_JOB_CATEGORY = \"Environmental and Health Safety\"\n",
    "        SAFETY_WORKBANK_JOB_INFO3 = SAFETY_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        SAFETY_WORKBANK_JOB_DESCRIPTION = SAFETY_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(SAFETY_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(SAFETY_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(SAFETY_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(SAFETY_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(SAFETY_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(SAFETY_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(SAFETY_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_YEAR_WE.append(SAFETY_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_EDUCATION.append(SAFETY_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(SAFETY_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-isaac",
   "metadata": {},
   "source": [
    "### CATEGORY - Medical and Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medical and Healthcare\n",
    "HEALTH_WORKBANK_URL = 'https://www.workbank.com/job/medical-healthcare-job-openings?wb_q='\n",
    "HEALTH_WORKBANK = requests.get(HEALTH_WORKBANK_URL)\n",
    "HEALTH_WORKBANK_soup = BeautifulSoup(HEALTH_WORKBANK.content, 'html.parser')\n",
    "HEALTH_WORKBANK_PP = HEALTH_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(HEALTH_WORKBANK_PP)!=0):\n",
    "    HEALTH_WORKBANK_NUMPAGES=len(HEALTH_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    HEALTH_WORKBANK_NUMPAGES=0\n",
    "HEALTH_WORKBANK_PAGES=[]\n",
    "if (HEALTH_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        HEALTH_WORKBANK_PAGES.append('https://www.workbank.com/job/medical-healthcare-job-openings?page='+ str(i))\n",
    "else:\n",
    "    HEALTH_WORKBANK_PAGES.append('https://www.workbank.com/job/medical-healthcare-job-openings?page=1')\n",
    "for i in range(len(HEALTH_WORKBANK_PAGES)):\n",
    "    HEALTH_WORKBANK_URLs = HEALTH_WORKBANK_PAGES[i]\n",
    "    HEALTH_WORKBANK_PAGE = requests.get(HEALTH_WORKBANK_URLs)\n",
    "    HEALTH_WORKBANK_PAGE_soup = BeautifulSoup(HEALTH_WORKBANK_PAGE.content, 'html.parser')\n",
    "    HEALTH_WORKBANK_JOBS = HEALTH_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    HEALTH_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(HEALTH_WORKBANK_JOBS))\n",
    "    HEALTH_WORKBANK_JOB_DATEs = HEALTH_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(HEALTH_WORKBANK_JOB_URLs)):\n",
    "        HEALTH_WORKBANK_JOB_PAGE = requests.get(HEALTH_WORKBANK_JOB_URLs[j])\n",
    "        HEALTH_WORKBANK_JOB_PAGE_soup = BeautifulSoup(HEALTH_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        HEALTH_WORKBANK_JOB_PAGE_INFO1 = HEALTH_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        HEALTH_WORKBANK_JOB_TITLE = HEALTH_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        HEALTH_WORKBANK_JOB_COMPANY = HEALTH_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        HEALTH_WORKBANK_JOB_SALARY = HEALTH_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        HEALTH_WORKBANK_JOB_DATEPOSTED = HEALTH_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        HEALTH_WORKBANK_JOB_LOCATION = HEALTH_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        HEALTH_WORKBANK_JOB_INFO2 = HEALTH_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        HEALTH_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(HEALTH_WORKBANK_JOB_INFO2))[0]\n",
    "        HEALTH_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(HEALTH_WORKBANK_JOB_INFO2))[0]\n",
    "        HEALTH_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        HEALTH_WORKBANK_JOB_CATEGORY = \"Medical and Healthcare\"\n",
    "        HEALTH_WORKBANK_JOB_INFO3 = HEALTH_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        HEALTH_WORKBANK_JOB_DESCRIPTION = HEALTH_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(HEALTH_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(HEALTH_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(HEALTH_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(HEALTH_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(HEALTH_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(HEALTH_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(HEALTH_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_YEAR_WE.append(HEALTH_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_EDUCATION.append(HEALTH_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(HEALTH_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-angle",
   "metadata": {},
   "source": [
    "### CATEGORY - Sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sciences\n",
    "SCIENCES_WORKBANK_URL = 'https://www.workbank.com/job/sciences-job-openings?wb_q='\n",
    "SCIENCES_WORKBANK = requests.get(SCIENCES_WORKBANK_URL)\n",
    "SCIENCES_WORKBANK_soup = BeautifulSoup(SCIENCES_WORKBANK.content, 'html.parser')\n",
    "SCIENCES_WORKBANK_PP = SCIENCES_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(SCIENCES_WORKBANK_PP)!=0):\n",
    "    SCIENCES_WORKBANK_NUMPAGES=len(SCIENCES_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    SCIENCES_WORKBANK_NUMPAGES=0\n",
    "SCIENCES_WORKBANK_PAGES=[]\n",
    "if (SCIENCES_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        SCIENCES_WORKBANK_PAGES.append('https://www.workbank.com/job/sciences-job-openings?page='+ str(i))\n",
    "else:\n",
    "    SCIENCES_WORKBANK_PAGES.append('https://www.workbank.com/job/sciences-job-openings?page=1')\n",
    "for i in range(len(SCIENCES_WORKBANK_PAGES)):\n",
    "    SCIENCES_WORKBANK_URLs = SCIENCES_WORKBANK_PAGES[i]\n",
    "    SCIENCES_WORKBANK_PAGE = requests.get(SCIENCES_WORKBANK_URLs)\n",
    "    SCIENCES_WORKBANK_PAGE_soup = BeautifulSoup(SCIENCES_WORKBANK_PAGE.content, 'html.parser')\n",
    "    SCIENCES_WORKBANK_JOBS = SCIENCES_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    SCIENCES_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(SCIENCES_WORKBANK_JOBS))\n",
    "    SCIENCES_WORKBANK_JOB_DATEs = SCIENCES_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(SCIENCES_WORKBANK_JOB_URLs)):\n",
    "        SCIENCES_WORKBANK_JOB_PAGE = requests.get(SCIENCES_WORKBANK_JOB_URLs[j])\n",
    "        SCIENCES_WORKBANK_JOB_PAGE_soup = BeautifulSoup(SCIENCES_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        SCIENCES_WORKBANK_JOB_PAGE_INFO1 = SCIENCES_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        SCIENCES_WORKBANK_JOB_TITLE = SCIENCES_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        SCIENCES_WORKBANK_JOB_COMPANY = SCIENCES_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        SCIENCES_WORKBANK_JOB_SALARY = SCIENCES_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        SCIENCES_WORKBANK_JOB_DATEPOSTED = SCIENCES_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        SCIENCES_WORKBANK_JOB_LOCATION = SCIENCES_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        SCIENCES_WORKBANK_JOB_INFO2 = SCIENCES_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        SCIENCES_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(SCIENCES_WORKBANK_JOB_INFO2))[0]\n",
    "        SCIENCES_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(SCIENCES_WORKBANK_JOB_INFO2))[0]\n",
    "        SCIENCES_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        SCIENCES_WORKBANK_JOB_CATEGORY = \"Sciences\"\n",
    "        SCIENCES_WORKBANK_JOB_INFO3 = SCIENCES_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        SCIENCES_WORKBANK_JOB_DESCRIPTION = SCIENCES_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(SCIENCES_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(SCIENCES_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(SCIENCES_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(SCIENCES_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(SCIENCES_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(SCIENCES_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(SCIENCES_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_YEAR_WE.append(SCIENCES_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_EDUCATION.append(SCIENCES_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(SCIENCES_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-participation",
   "metadata": {},
   "source": [
    "### CATEGORY - Actuarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actuarial\n",
    "ACTUARIAL_WORKBANK_URL = 'https://www.workbank.com/job/hiring-actuarial'\n",
    "ACTUARIAL_WORKBANK = requests.get(ACTUARIAL_WORKBANK_URL)\n",
    "ACTUARIAL_WORKBANK_soup = BeautifulSoup(ACTUARIAL_WORKBANK.content, 'html.parser')\n",
    "ACTUARIAL_WORKBANK_PP = ACTUARIAL_WORKBANK_soup.find_all('div',{'class':'wb-pagination'})\n",
    "if (len(ACTUARIAL_WORKBANK_PP)!=0):\n",
    "    ACTUARIAL_WORKBANK_NUMPAGES=len(ACTUARIAL_WORKBANK_PP[0].select(\"option\"))\n",
    "else:\n",
    "    ACTUARIAL_WORKBANK_NUMPAGES=0\n",
    "ACTUARIAL_WORKBANK_PAGES=[]\n",
    "if (ACTUARIAL_WORKBANK_NUMPAGES!=0):\n",
    "    for i in range(1,IT_WORKBANK_NUMPAGES+1):\n",
    "        ACTUARIAL_WORKBANK_PAGES.append('https://www.workbank.com/job/hiring-actuarial?page='+ str(i))\n",
    "else:\n",
    "    ACTUARIAL_WORKBANK_PAGES.append('https://www.workbank.com/job/hiring-actuarial?page=1')\n",
    "for i in range(len(ACTUARIAL_WORKBANK_PAGES)):\n",
    "    ACTUARIAL_WORKBANK_URLs = ACTUARIAL_WORKBANK_PAGES[i]\n",
    "    ACTUARIAL_WORKBANK_PAGE = requests.get(ACTUARIAL_WORKBANK_URLs)\n",
    "    ACTUARIAL_WORKBANK_PAGE_soup = BeautifulSoup(ACTUARIAL_WORKBANK_PAGE.content, 'html.parser')\n",
    "    ACTUARIAL_WORKBANK_JOBS = ACTUARIAL_WORKBANK_PAGE_soup.find_all('a',{'class':'clearfix'})\n",
    "    ACTUARIAL_WORKBANK_JOB_URLs = re.findall(r'(?s)(?<=href=\").*?(?=\"><h5)',str(ACTUARIAL_WORKBANK_JOBS))\n",
    "    ACTUARIAL_WORKBANK_JOB_DATEs = ACTUARIAL_WORKBANK_PAGE_soup.find_all('p',{'class':'publish-date-card mt-1 text-left mb-0'})\n",
    "    for j in range(len(ACTUARIAL_WORKBANK_JOB_URLs)):\n",
    "        ACTUARIAL_WORKBANK_JOB_PAGE = requests.get(ACTUARIAL_WORKBANK_JOB_URLs[j])\n",
    "        ACTUARIAL_WORKBANK_JOB_PAGE_soup = BeautifulSoup(ACTUARIAL_WORKBANK_JOB_PAGE.content, 'html.parser')\n",
    "        ACTUARIAL_WORKBANK_JOB_PAGE_INFO1 = ACTUARIAL_WORKBANK_JOB_PAGE_soup.find('article',{'class':'job-ad-text-center pl-3'})\n",
    "        ACTUARIAL_WORKBANK_JOB_TITLE = ACTUARIAL_WORKBANK_JOB_PAGE_INFO1.contents[0].text.strip()\n",
    "        ACTUARIAL_WORKBANK_JOB_COMPANY = ACTUARIAL_WORKBANK_JOB_PAGE_INFO1.contents[1].text.strip()\n",
    "        ACTUARIAL_WORKBANK_JOB_SALARY = ACTUARIAL_WORKBANK_JOB_PAGE_INFO1.contents[4].text.strip()\n",
    "        ACTUARIAL_WORKBANK_JOB_DATEPOSTED = ACTUARIAL_WORKBANK_JOB_DATEs[j].text.strip()\n",
    "        ACTUARIAL_WORKBANK_JOB_LOCATION = ACTUARIAL_WORKBANK_JOB_PAGE_soup.find('a',{'class':'cls-links'}).text.strip()\n",
    "        ACTUARIAL_WORKBANK_JOB_INFO2 = ACTUARIAL_WORKBANK_JOB_PAGE_soup.find('ul',{'class':'job-ad-des-ul mb-0'})\n",
    "        ACTUARIAL_WORKBANK_JOB_STATUS = re.findall(r'(?s)(?<=Job Type</h5><p>).*?(?=</p>)',str(ACTUARIAL_WORKBANK_JOB_INFO2))[0]\n",
    "        ACTUARIAL_WORKBANK_JOB_EDUCATION = re.findall(r'(?s)(?<=Educational Attainment</h5><p>).*?(?=</p>)',str(ACTUARIAL_WORKBANK_JOB_INFO2))[0]\n",
    "        ACTUARIA_WORKBANK_JOB_YEARS_WE = re.findall(r'(?s)(?<=Years of Work Experience</h5><p>).*?(?=</p>)',str(IT_WORKBANK_JOB_INFO2))[0]\n",
    "        ACTUARIAL_WORKBANK_JOB_CATEGORY = \"Actuarial\"\n",
    "        ACTUARIAL_WORKBANK_JOB_INFO3 = ACTUARIAL_WORKBANK_JOB_PAGE_soup.find('article',{'class':'pl-4 pr-4 pb-0 pt-4'})\n",
    "        ACTUARIAL_WORKBANK_JOB_DESCRIPTION = ACTUARIAL_WORKBANK_JOB_INFO3.contents[1].getText(separator=u' ')\n",
    "        WORKBANK_JOB_TITLE.append(ACTUARIAL_WORKBANK_JOB_TITLE)\n",
    "        WORKBANK_JOB_CATEGORY.append(ACTUARIAL_WORKBANK_JOB_CATEGORY)\n",
    "        WORKBANK_JOB_COMPANY.append(ACTUARIAL_WORKBANK_JOB_COMPANY)\n",
    "        WORKBANK_JOB_DATE.append(ACTUARIAL_WORKBANK_JOB_DATEPOSTED)\n",
    "        WORKBANK_JOB_LOCATION.append(ACTUARIAL_WORKBANK_JOB_LOCATION)\n",
    "        WORKBANK_JOB_STATUS.append(ACTUARIAL_WORKBANK_JOB_STATUS)\n",
    "        WORKBANK_JOB_SALARY.append(ACTUARIAL_WORKBANK_JOB_SALARY)\n",
    "        WORKBANK_JOB_YEAR_WE.append(ACTUARIA_WORKBANK_JOB_YEARS_WE)\n",
    "        WORKBANK_JOB_EDUCATION.append(ACTUARIAL_WORKBANK_JOB_EDUCATION)\n",
    "        WORKBANK_JOB_DESCRIPTION.append(ACTUARIAL_WORKBANK_JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-schedule",
   "metadata": {},
   "source": [
    "### Data check\n",
    "Print the acquired data set to check the gathered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-counter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workbank={'Website': \"Workbank\" ,\n",
    "          'Job Title': WORKBANK_JOB_TITLE, \n",
    "          'Category': WORKBANK_JOB_CATEGORY, \n",
    "          'Company': WORKBANK_JOB_COMPANY, \n",
    "          'Date Posted': WORKBANK_JOB_DATE, \n",
    "          'Location': WORKBANK_JOB_LOCATION, \n",
    "          'Status': WORKBANK_JOB_STATUS, \n",
    "          'Salary': WORKBANK_JOB_SALARY, \n",
    "          'Education': WORKBANK_JOB_EDUCATION, \n",
    "          'Years of Work Experience': WORKBANK_JOB_YEAR_WE,\n",
    "          'Job Description': WORKBANK_JOB_DESCRIPTION}\n",
    "workbank_df = pd.DataFrame(data=workbank)\n",
    "workbank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-chinese",
   "metadata": {},
   "source": [
    "### Parsing the Data to JSON\n",
    "\n",
    "Store the gathered data into a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = workbank_df.to_json(orient='records')\n",
    "parsed = json.loads(data)\n",
    "json.dumps(parsed, indent=4) \n",
    "with open('workbank.json', 'w') as json_file:\n",
    "    json.dump(parsed, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
