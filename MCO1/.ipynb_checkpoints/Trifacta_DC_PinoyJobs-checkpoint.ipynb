{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d59761-df61-4efb-9e70-315de6d0ba96",
   "metadata": {},
   "source": [
    "# Data Cleaning (Pinoy Jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b251b-6584-4593-802b-25113ddb2506",
   "metadata": {},
   "source": [
    "## Imports used (to be described)\n",
    "\n",
    "* `os` - a module that provides functions to interact with the operating system.\n",
    "* `pandas` - is a tool that helps analyze data.\n",
    "* `numpy` - Library that contains multiple functions that help ease the work with arrays, matrices, and alike to better reassemble data.\n",
    "* `json` - enables import and export from and to JSON files\n",
    "* `re` - Short for Regular Expressions, help recognize patterns on strings of data and is used to orderly reassemble them.\n",
    "* `gensim` - Library that efficiently handles large, unmanaged text collections of data.\n",
    "* `nltk` - Short for Natural Language Toolkit. It helps the program to apply human language data to statistical natural language.\n",
    "* `requests` - Requests allows the program to send HTTP requests easily.\n",
    "* `Seaborn` - A library in python that is used to better visualize data through drawing informative graphs.\n",
    "* `math` - Imported library that allows quick computations of mathematical tasks\n",
    "* `calplot` - \n",
    "* `matplotlib.pyplot` -\n",
    "* `gensim.utils` `simple_preprocess` - used to preprocess text by making them lower-cased, and transforming the words to their original form (de-tokenizing)\n",
    "* `gensim.parsing.preprocessing` `STOPWORDS` - stop words common words that do not have value and are often removed in pre-processing\n",
    "* `gensim` `corpora` - used to work with corpus and words\n",
    "* `gensim` `models` - used for topic modelling and model training\n",
    "* `nltk.stem` `WordNetLemmatizer` - used for grouping similar strings together\n",
    "* `bs4` `BeautifulSoup` - library used to web scrape HTML from websites\n",
    "* `datetime` `datetime` - An imported module in python to create an object that properly resembles date and time. Used for converting string of time into datetime format to month, day, and year.\n",
    "* `datetime` `timedelta` - used for finding delta of time ago with time scraped if date has minutes, hours, days, or weeks ago\n",
    "* `dateutil.relativedelta` `relativedelta` - used for finding delta of time ago with time scraped if date has months and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efac6b85-2992-44d0-8f6c-53ecd2ad1212",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dd447b85e155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\translate\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbleu_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentence_bleu\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbleu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mribes_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentence_ribes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mribes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeteor_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmeteor_score\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmeteor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malignment_error_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_decoder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\translate\\meteor_score.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyCorpusLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m abc = LazyCorpusLoader(\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \"\"\"\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaintext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\plaintext.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPlaintextCorpusReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCorpusReader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m     23\u001b[0m     \u001b[0mReader\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcorpora\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mconsist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mplaintext\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mParagraphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\plaintext.py\u001b[0m in \u001b[0;36mPlaintextCorpusReader\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mword_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWordPunctTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0msent_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLazyLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/english.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mpara_block_reader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_blankline_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import requests\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import calplot\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "today = datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b685c7-10c1-4da0-8347-e70c69d0af7e",
   "metadata": {},
   "source": [
    "### Importing JSON File\n",
    "\n",
    "Testing the importing of the created JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763a1c1-bfac-48e3-8061-3d7b78ba2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read from Json File \n",
    "pinoyjobs_df_json = pd.read_json (r'PinoyJobs Data\\pinoy_jobs.json')\n",
    "pinoyjobs_df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44575124-ce19-4804-ab74-0c3299470028",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinoyjobs_df_json[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f839f9-d4c0-4622-8840-7d6679c62e3e",
   "metadata": {},
   "source": [
    "### Getting the Date Posted\n",
    "Taking a look at the Date Posted column of the created dataframe for PinoyJobs, we can see that it is not formatted correctly, therefore we will be reformatting it to YYYY-MM-DD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06cc31-9472-4e78-bc3e-b8e0d57e7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the Date Format (PinoyJobs)\n",
    "new_date_posted = []        \n",
    "for index, row in pinoyjobs_df_json.iterrows():\n",
    "    then = datetime.strptime(row[\"Date Posted\"], 'Posted on %B %d, %Y')\n",
    "    new_date_posted.append(then)\n",
    "pinoyjobs_df_json[\"Date Posted\"] = new_date_posted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec0f09-83d6-4cfb-b2cc-4315582aabed",
   "metadata": {},
   "source": [
    "### Salary\n",
    "\n",
    "As we can observe from the Salary column, we can see that it has two components: minimum salary and maximum salary since it takes the range of the salary. We will be putting those two components into two different columns: Min Salary and Max Salary.\n",
    "### Getting the Min Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea02d7-5a9a-4538-b6ba-9b7be092f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the MIN salary (PinoyJobs)\n",
    "def salary_seperatorinator_MIN_PJ(salary):\n",
    "    if not len(salary):\n",
    "        salary = \"Not Specified\"\n",
    "    str2 = (salary.replace('₱', ''))\n",
    "    str3 = (str2.replace(',', ''))\n",
    "    stroutput = [int(s) for s in str3.split() if s.isdigit()]\n",
    "    if not len(stroutput):\n",
    "        return salary\n",
    "    else:\n",
    "        return stroutput[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09adecb9-b6c2-4d78-bcc5-e44023bfa4a1",
   "metadata": {},
   "source": [
    "### Getting the Max Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80150492-1116-4d77-bafc-a5a8d8b83c40",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Gets the MAX salary (PinoyJobs)\n",
    "def salary_seperatorinator_MAX_PJ(salary):\n",
    "    if not len(salary):\n",
    "        salary = \"Not Specified\"\n",
    "    str2 = (salary.replace('₱', ''))\n",
    "    str3 = (str2.replace(',', ''))\n",
    "    stroutput = [int(s) for s in str3.split() if s.isdigit()]\n",
    "    if not len(stroutput):\n",
    "        return salary\n",
    "    else:\n",
    "        try:\n",
    "            return stroutput[1]\n",
    "        except:\n",
    "            return salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82e776-de56-4d8e-ba04-d3d7752035c3",
   "metadata": {},
   "source": [
    "### Getting the Years of Experience from Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0af496-ef8b-4a17-84f4-fa923d32aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to get the years of experience from description\n",
    "def find_experienceinator(description):\n",
    "    yearoutput = [int(s) for s in description.split() if s.isdigit()]\n",
    "    if len(yearoutput) > 0:\n",
    "        if (yearoutput[0] < 20):\n",
    "            if len(yearoutput) > 1:\n",
    "                return (\"{0} - {1}\").format(yearoutput[0],yearoutput[1])\n",
    "            elif len(yearoutput) == 1:\n",
    "                return (\"{}\").format(yearoutput[0])\n",
    "            else:\n",
    "                return \"Not Specified\"\n",
    "        else:\n",
    "            return \"Not Specified\"\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3f40f-1c46-47db-acbe-5e35732e9030",
   "metadata": {},
   "source": [
    "### Getting the Min Years\n",
    "\n",
    "As from the Min and Max salaries, we can also observe that there are two components from the years of experience sometimes. They will be separated into Maximum Years of Experience, and Minimum Years of Experience. If there are two components found, we will take the first one, else if there is only one digit found, we take that instead for the min years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07f447-349d-4a82-b135-d0f6cffee43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the MAX year (PinoyJobs)\n",
    "def year_seperatorinator_MIN_PJ(year_exp):\n",
    "    if not len(year_exp):\n",
    "        year_exp = \"Not Specified\"\n",
    "    str2 = (year_exp.replace('-', ' '))\n",
    "    str3 = (str2.replace(',', ' '))\n",
    "    stroutput = [int(s) for s in str3.split() if s.isdigit()]\n",
    "    if not len(stroutput):\n",
    "        return year_exp\n",
    "    else:\n",
    "        try:\n",
    "            return stroutput[0]\n",
    "        except:\n",
    "            return year_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46e5ee-e37b-48a0-86d2-f25cc33a9ec8",
   "metadata": {},
   "source": [
    "### Getting the Max Years\n",
    "Extracting Maximum Years from the years of experience. Like the Minimum Years, we look at the component(s) in the years of experience, if we find two, we take the latter, else if there is only one, then we take that instead for the max years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa67639-c823-4ca9-bcf8-be9e80fbe527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the MAX year (PinoyJobs)\n",
    "def year_seperatorinator_MAX_PJ(year_exp):\n",
    "    if not len(year_exp):\n",
    "        year_exp = \"Not Specified\"\n",
    "    str2 = (year_exp.replace('-', ' '))\n",
    "    str3 = (str2.replace(',', ''))\n",
    "    stroutput = [int(s) for s in str3.split() if s.isdigit()]\n",
    "    if not len(stroutput):\n",
    "        return year_exp\n",
    "    else:\n",
    "        try:\n",
    "            return stroutput[1]\n",
    "        except:\n",
    "            return stroutput[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5910b-1f35-426b-9c7c-04b1ce87ece0",
   "metadata": {},
   "source": [
    "### Getting Educational Attainment\n",
    "\n",
    "In the details we can further find that it sometimes contains the Educational Attainment as part of the requirements.\n",
    "\n",
    "There are three keywords that we will use to find these such as \"Bachelor\", \"Degree\", and \"BS\". If the keywords are found, we will write in \"Bachelor's Degree\" for the Education, otherwise \"Not Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea9d5b-b6d0-4580-ad18-7b7b974154e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_education(description):\n",
    "    eduoutput = (description.replace('/', ''))\n",
    "    education_list = ['Bachelor','Degree','BS']\n",
    "    if any(x in eduoutput for x in education_list):\n",
    "        return \"Bachelor's Degree\"\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40627efc-b924-4a99-b4a7-fe1ba6d71e6f",
   "metadata": {},
   "source": [
    "### Getting the Work Experience in Years\n",
    "From the description, we find the number of years by looking up anything related to the spelling of years in any capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8b960-87bf-447b-9ad0-3581fde1f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_experienceinator_test(description):\n",
    "    yearoutput = [int(s) for s in description.split() if s.isdigit()]\n",
    "    find_list = [\"year\",\"Years\",\"YEARS\",\"Year\",\"YEAR\"]\n",
    "    if (len(re.findall(r\"\\d-\\d \\w+\",description)) > 0):\n",
    "        return (re.findall(r\"\\d-\\d \\w+\",description))[0]\n",
    "\n",
    "    elif (len(re.findall(r\"\\d \\w+ \\w+ \\w+\",description)) > 0):\n",
    "        return (re.findall(r\"\\d+ \\w+ \\w+ \\w+\",description))[0]\n",
    "\n",
    "    elif (len(re.findall(r\"\\d+ year\",description)) > 0):\n",
    "        return (re.findall(r\"\\d+\",description))[0]\n",
    "\n",
    "    elif (len(re.findall(r\"\\w+ year\",description)) > 0):\n",
    "        return (re.findall(r\"\\w+\",description))[0]\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a47d34-bae5-414c-b050-14872def3347",
   "metadata": {},
   "source": [
    "### Getting the Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe653e-f213-4870-a778-41e70e52f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_cleanator_PJ(status):\n",
    "    if (len(re.findall(r\"Full\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Full Time\")\n",
    "    elif(len(re.findall(r\"Part\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Part Time\")\n",
    "    elif(len(re.findall(r\"Contract\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Contract\")\n",
    "    elif(len(re.findall(r\"Project\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Project Base\")    \n",
    "    elif(len(re.findall(r\"Freelance\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Freelance\")        \n",
    "    elif(len(re.findall(r\"OJT\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"OJT\")    \n",
    "    elif(len(re.findall(r\"Intern\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"OJT\")    \n",
    "    elif(len(re.findall(r\"Regular\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Full Time\")\n",
    "    elif(len(re.findall(r\"Temporary\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Contract\")   \n",
    "    elif(len(re.findall(r\"Permanent\",status, re.IGNORECASE)) > 0):\n",
    "        return (\"Full Time\")  \n",
    "    else: return (\"Not Specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c662a71-f89c-41d7-be2b-41fe35e36e32",
   "metadata": {},
   "source": [
    "### Getting the Job Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c577bc-6371-44a7-9645-99643d5de2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_cleanator_PJ(location):\n",
    "    if (len(re.findall(r\"Home\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Work From Home\")\n",
    "    elif (len(re.findall(r\"\\w+ City\",location, re.IGNORECASE)) > 0):\n",
    "        output = (re.findall(r\"\\w+ City\",location, re.IGNORECASE))\n",
    "        return (output[0])\n",
    "    elif (len(re.findall(r\"Metro Manila\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Metro Manila\")\n",
    "    elif (len(re.findall(r\"Manila\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Manila City\")\n",
    "    elif (len(re.findall(r\"Laguna\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Laguna\")\n",
    "    elif (len(re.findall(r\"Pasig\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Pasig City\")\n",
    "    elif (len(re.findall(r\"Paranaque\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Paranaque\")\n",
    "    elif (len(re.findall(r\"Pampanga\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Pampanga\")\n",
    "    elif (len(re.findall(r\"Batangas\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Batangas\")\n",
    "    elif (len(re.findall(r\"Cavite\",location, re.IGNORECASE)) > 0):\n",
    "        return (\"Cavite\")\n",
    "    else:\n",
    "        return location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a280bb-d908-4a88-9bb6-f7c967fe4a27",
   "metadata": {},
   "source": [
    "### Categorizing for Combined Dataset\n",
    "\n",
    "* <a href=\"https://www.bestcolleges.com/careers/stem/\">\n",
    "    bestcolleges.com\n",
    "</a> \n",
    "\n",
    "    - Basis for careers from \"IT, Programming, Systems & Networks\" AND \"Jobs in Web Development & Design, HTML, SEO\" were classified as IT\n",
    "    - Basis for careers from \"Jobs in Engineering, Construction & Electrical\" and \"Jobs in Manufacturing, Production\" were classified as Engineering\n",
    "    - Basis for careers from \"Jobs in Sciences, Lab, R&D\" were classified as Science\n",
    "    - Basis for careers from \"Jobs in Nursing, Medical, Dental & Health\" were classified as Medicine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4eea69-e2fb-4eea-b5cb-8dbe6cc209ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_deciderinator_PJ(field):\n",
    "    if (len(re.findall(r\"Jobs in IT, Programming, Systems & Networks\",field, re.IGNORECASE)) > 0):\n",
    "        return (\"IT\")\n",
    "    elif (len(re.findall(r\"Jobs in Engineering, Construction & Electrical\",field, re.IGNORECASE)) > 0):\n",
    "        return (\"Engineering\")\n",
    "    elif (len(re.findall(r\"Jobs in Manufacturing, Production\",field, re.IGNORECASE)) > 0):\n",
    "        return (\"Engineering\")\n",
    "    elif (len(re.findall(r\"Jobs in Nursing, Medical, Dental & Health\",field, re.IGNORECASE)) > 0):\n",
    "        return (\"Medicine\")\n",
    "    elif (len(re.findall(r\"Jobs in Web Development & Design, HTML, SEO\",field, re.IGNORECASE)) > 0):\n",
    "        return (\"IT\")\n",
    "    elif (len(re.findall(r\"Jobs in Sciences, Lab, R&D\",field, re.IGNORECASE)) > 0):\n",
    "        return (\"Science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a86547-0f81-4443-a08a-ec28abffafe4",
   "metadata": {},
   "source": [
    "### Applying Functions\n",
    "\n",
    "Apply all functions for data clean up to their specified feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773730a-38c2-4d09-97a2-7d07cf9b9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinoyjobs_df_json[\"Min Salary\"]= pinoyjobs_df_json[\"Salary\"].apply(salary_seperatorinator_MIN_PJ) \n",
    "pinoyjobs_df_json[\"Max Salary\"]= pinoyjobs_df_json[\"Salary\"].apply(salary_seperatorinator_MAX_PJ) \n",
    "pinoyjobs_df_json[\"Years of Work Experience\"] = pinoyjobs_df_json[\"Job Description\"].apply(find_experienceinator_test)\n",
    "pinoyjobs_df_json[\"Education\"] = pinoyjobs_df_json[\"Job Description\"].apply(find_education)\n",
    "pinoyjobs_df_json[\"Min Years of Work Experience\"]= pinoyjobs_df_json[\"Years of Work Experience\"].apply(year_seperatorinator_MIN_PJ) \n",
    "pinoyjobs_df_json[\"Max Years of Work Experience\"]= pinoyjobs_df_json[\"Years of Work Experience\"].apply(year_seperatorinator_MAX_PJ) \n",
    "pinoyjobs_df_json[\"Status\"]= pinoyjobs_df_json[\"Status\"].apply(status_cleanator_PJ) \n",
    "pinoyjobs_df_json[\"Location\"]= pinoyjobs_df_json[\"Location\"].apply(location_cleanator_PJ) \n",
    "pinoyjobs_df_json[\"Field\"]= pinoyjobs_df_json[\"Category\"].apply(field_deciderinator_PJ) \n",
    "pinoyjobs_df_json.drop(\"Salary\", inplace=True, axis=1)\n",
    "pinoyjobs_df_json.drop(\"Years of Work Experience\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318260c-400d-4a25-8b0d-1daad14cfac8",
   "metadata": {},
   "source": [
    "### Pinoy Jobs Dataset\n",
    "The data that we will gather will contain the following variables:\n",
    "- `Job Title` - The title of the job position\n",
    "- `Category` - The type of the job, or job category\n",
    "- `Company` - Employer\n",
    "- `Date Posted` - date when the listing was posted in the sites\n",
    "- `Location` - location of the job listing where the applicants are to be deployed to. If the job is available as Work From Home (WFH), it will be marked \"Homebased\"\n",
    "- `Status` - Whether the job is available for full-time or part-time\n",
    "- `Salary` - monetary compensation range in Philippine Peso (PHP)\n",
    "- `Years of Work Experience` - years of experienced required\n",
    "- `Description` - detailed description of the job listing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9b107-0357-494f-8235-b0f02cafe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinoyjobs_df_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656fd38-559a-455b-8a2c-5a5b0673a820",
   "metadata": {},
   "source": [
    "### Parsing to CSV File\n",
    "\n",
    "Store the cleaned gathered data into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01fce9-6cae-48a8-97d2-66767a930ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinoyjobs_df_json.to_csv ('Cleaned Data CSV\\pinoyjobs_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d8ebc-7e8f-4855-b6cb-2fb7e2b9da22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
